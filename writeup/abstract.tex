
% Place the contents of your abstract between the
% \begin{abstract} and \end{abstract} decorators.

\begin{abstract}

This paper analyzes a well known division of reinforcement learning known
as the multi-armed bandit problem. The multi-armed bandit problem
attempts to determine the best policy when faced with multiple
choices. We analyze two different policies for picking machines: upper
confidence bound (\textlcsc{UCB1}) and $\mathcal{E}_n$
-\textlcsc{greedy}. [alg] was a better algorithm due to...


% The \textbf{} command makes the specified text bold. The \emph{} or
% \textit{} command are used to italicize text. In general, text is never
% underlined.

% DON'T FORGET TO MATCH EACH OPEN BRACE WITH A CLOSING BRACE!
\end{abstract}

